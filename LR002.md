##使用极大似然估计解释最小二乘
##### 误差

<img src="https://note.youdao.com/yws/api/personal/file/WEB8d120b4bb8785c41f2cdc4a5de0e9361?method=download&shareKey=4cd503bdaee9959e6af0ebd03b1b0685">
$$y^{i} = \theta^{T}x^{i} + \varepsilon ^{\left( i \right)}$$

误差$$\varepsilon^{(i)}(1\leqslant i\leqslant m)$$是独立同分布的，服从均值为0，方差为某定值$$\sigma ^2$$的高斯分布。
各个细枝末节构成了一个个震荡，我们如果看这些东西看做为随机变量，当足够多的随机变量进行叠加之后，形成的分布，根据中心极限定理，它的分布为**正态分布**

原因：中心极限定理

- 为什么均值一定为0？

如果不为0，我们的表达式中有一个$$\theta_0$$为截距，可以使图像的均值为0



## 似然函数 $$y^{(i)} = \theta^{(i)} + \varepsilon^{\left( i \right)}$$
对似然函数进行推导
$$p\left( \epsilon ^{\left( i \right)} \right) =\frac{1}{\sqrt{2\pi}\sigma}\exp \left( -\frac{\left( \epsilon ^{\left( i \right)} \right) ^2}{2\sigma ^2} \right) 
$$

我们知道$$y^{i} = \theta^{T}x^{i} + \varepsilon ^{\left( i \right)}$$

$$p\left( y^{\left( i \right)}|x^{\left( i \right)};\theta \right) =\frac{1}{\sqrt{2\pi}\sigma}\exp \left( -\frac{\left( y^{\left( i \right)}-\theta ^Tx^{\left( i \right)} \right) ^2}{2\sigma ^2} \right) 
$$

既然独立，那么$$y_1,y_2,...,y_m$$ 联合概率就是各自边缘概率的乘积，这个乘积叫做似然函数

$$L\left( \theta \right) =\prod_{i=1}^m{p\left( y^{\left( i \right)}|x^{\left( i \right)};\theta \right)}
$$

$$=\prod_{i=1}^m{\frac{1}{\sqrt{2\pi}\sigma}\exp \left( -\frac{\left( y^{\left( i \right)}-\theta ^Tx^{\left( i \right)} \right) ^2}{2\sigma ^2} \right)}$$

取对数，得：

<img src="https://note.youdao.com/yws/api/personal/file/WEBa36000ff2b3da7a7c0ab11f377a56682?method=download&shareKey=9d24997dfd3630a84160c0d29eaf0a80" width="500">

我们用的方法为最大似然估计，目的是为了使$$l\left( \theta \right) $$取最大值，因此我们需要求$$J\left( \theta \right) $$的最小值(因此，我们认为$$J\left( \theta \right) $$为**损失函数**)

**最小二乘**：以$$J(\theta)$$目标函数的估计方式，因此上文的推导过程就是最小二乘的本质


